{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create examples of network output for figure panels\n",
    "Created by: Yarden Cohen\\\n",
    "Date: June 2021\\\n",
    "This notebook allows loading specific saved TweetyNet models and examining their outputs.\n",
    "Cells in this notebook will also hold code to create figure panels showing such network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from argparse import ArgumentParser\n",
    "import configparser  # used to load 'min_segment_dur.ini'\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprojroot\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vak import config, io, models, transforms\n",
    "from vak.datasets.vocal_dataset import VocalDataset\n",
    "import vak.device\n",
    "import vak.files\n",
    "from vak.labeled_timebins import lbl_tb2segments, majority_vote_transform, lbl_tb_segment_inds_list,     remove_short_segments\n",
    "from vak.core.learncurve import train_dur_csv_paths as _train_dur_csv_paths\n",
    "from vak.logging import log_or_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network_results(path_to_config=None,\n",
    "                        csv_path=None,\n",
    "                        labelmap_path=None,\n",
    "                        checkpoint_path=None,\n",
    "                        window_size = 370,\n",
    "                        min_segment_dur = 0.01,\n",
    "                        num_workers = 12,\n",
    "                        device='cuda',\n",
    "                        spect_key='s',\n",
    "                        timebins_key='t',\n",
    "                        freq_key = 'f',\n",
    "                        test_all_files=False):\n",
    "    if path_to_config:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose and indicate the checkpoint of a saved model and a csv defining data\n",
    "# This is done without a config file to allow flexibility\n",
    "\n",
    "csv_path = \"D:\\\\Users\\\\yarde\\\\vak_project\\\\Koumura2016\\\\Bird1\\\\config_BirdsongRecognition_bird01_w700_eval.toml\"\n",
    "labelmap_path = Path()\n",
    "checkpoint_path = \"\"\n",
    "\n",
    "# config parameters:\n",
    "window_size = 370\n",
    "min_segment_dur = 0.01\n",
    "num_workers = 12\n",
    "device='cuda'\n",
    "spect_key='s'\n",
    "timebins_key='t'\n",
    "freq_key = 'f'\n",
    "#spect_standardizer = \n",
    "with labelmap_path.open('r') as f:\n",
    "        labelmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a csv and create a new one with all splits marked as 'test'\n",
    "temp_df = pd.read_csv(csv_path)\n",
    "temp_df['split'] = 'test'\n",
    "temp_df.to_csv(csv_path.parent.joinpath(csv_path.stem + '_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare evaluation data\n",
    "item_transform = transforms.get_defaults('eval',\n",
    "                                             spect_standardizer=None,\n",
    "                                             window_size=window_size,\n",
    "                                             return_padding_mask=True,\n",
    "                                             )\n",
    "\n",
    "eval_dataset = VocalDataset.from_csv(csv_path=csv_path,\n",
    "                                     split='test',\n",
    "                                     labelmap=labelmap,\n",
    "                                     spect_key=spect_key,\n",
    "                                     timebins_key=timebins_key,\n",
    "                                     item_transform=item_transform,\n",
    "                                     )\n",
    "\n",
    "eval_data = torch.utils.data.DataLoader(dataset=eval_dataset,\n",
    "                                        shuffle=False,\n",
    "                                        # batch size 1 because each spectrogram reshaped into a batch of windows\n",
    "                                        batch_size=1,\n",
    "                                        num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model_config_map = {'TweetyNet': {'loss': {}, 'metrics': {}, 'network': {}, 'optimizer': {'lr': 0.001}}}\n",
    "input_shape = eval_dataset.shape\n",
    "# if dataset returns spectrogram reshaped into windows,\n",
    "# throw out the window dimension; just want to tell network (channels, height, width) shape\n",
    "if len(input_shape) == 4:\n",
    "    input_shape = input_shape[1:]\n",
    "\n",
    "models_map = models.from_model_config_map(\n",
    "    model_config_map,\n",
    "    num_classes=len(labelmap),\n",
    "    input_shape=input_shape\n",
    ")\n",
    "model_name = 'TweetyNet'\n",
    "model = models_map['TweetyNet']\n",
    "model.load(checkpoint_path)\n",
    "#metrics = model.metrics  # metric name -> callable map we use below in loop\n",
    "if device is None:\n",
    "    device = vak.device.get_default_device()\n",
    "pred_dict = model.predict(pred_data=eval_data,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data matrices for the model output time aligned to annotated model input\n",
    "file_number = 0\n",
    "time_window = [0.01,1.01]\n",
    "freq_window = [500.0,4000.0]\n",
    "\n",
    "annotation_df = pd.DataFrame(eval_dataset.annots[file_number].seq.as_dict())\n",
    "csv_df = pd.read_csv(eval_dataset.csv_path)\n",
    "spect_path = Path(np.array(csv_df[csv_df.split=='test'].spect_path)[file_number])\n",
    "spect = vak.files.spect.load(spect_path)[spect_key]\n",
    "t_vec = vak.files.spect.load(spect_path)[timebins_key]\n",
    "f_vec = vak.files.spect.load(spect_path)[freq_key]\n",
    "timebin_indices = np.where((t_vec >= time_window[0]) & (t_vec <= time_window[1]))[0]\n",
    "extent = [np.min(t_vec),np.max(t_vec),np.min(f_vec),np.max(f_vec)]\n",
    "model_output = pred_dict[spect_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "figsize = (5,10)\n",
    "fig, axs = plt.subplots(3,figsize=figsize)\n",
    "fig.suptitle('Example file ' + spect_path)\n",
    "axs[1].imshow(spect,aspect='auto',extent=extent)\n",
    "axs[1].set_xlim(time_window)\n",
    "axs[1].set_ylim(freq_window)\n",
    "axs[2].imshow(model_output,aspect='auto',extent=[extend[0],extent[1],0,np.shape(model_output)[1]])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
